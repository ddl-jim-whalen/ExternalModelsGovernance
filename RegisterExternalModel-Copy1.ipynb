{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea60d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7260ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Initialize MLFlow client\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# External model URI (for example, on AWS S3 or another location)\n",
    "external_model_uri = \"s3://my-bucket/my-model\"\n",
    "\n",
    "# Register the model with a name, linking to the external model URI\n",
    "model_details = client.create_registered_model(name=\"S3_ExternalModel\")\n",
    "\n",
    "# Create a new version of the registered model pointing to the external URI\n",
    "client.create_model_version(name=\"S3_ExternalModel\", source=external_model_uri, run_id=None)\n",
    "\n",
    "print(f\"Model version registered: {model_details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da2bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Initialize MLFlow client\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# External model URI \n",
    "external_model_uri = \"https://huggingface.co/openai/whisper-large-v3-turbo/tree/main\"\n",
    "\n",
    "# Register the model with a name, linking to the external model URI\n",
    "model_details = client.create_registered_model(name=\"Open_AIWhisper\")\n",
    "\n",
    "# Create a new version of the registered model pointing to the external URI\n",
    "client.create_model_version(name=\"Open_AIWhisper\", source=external_model_uri, run_id=None)\n",
    "\n",
    "print(f\"Model version registered: {model_details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76bd47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Initialize MLFlow client\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "\n",
    "# Register the model with a name, linking to the external model URI\n",
    "model_details = client.create_registered_model(name=\"Shell1\")\n",
    "\n",
    "# Create a new version of the registered model pointing to the external URI\n",
    "client.create_model_version(name=\"Shell1\", source='', run_id=None)\n",
    "\n",
    "print(f\"Model version registered: {model_details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45e999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Initialize MLFlow client\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "\n",
    "# Register the model with a name, linking to the external model URI\n",
    "model_details = client.create_registered_model(name=\"Shell2\")\n",
    "\n",
    "# Create a new version of the registered model pointing to the external URI\n",
    "client.create_model_version(name=\"Shell2\", source=None, run_id=None)\n",
    "\n",
    "print(f\"Model version registered: {model_details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430c5182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "# Directory where the empty model file will be created\n",
    "model_dir = \"empty_model\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Path to the empty model file\n",
    "empty_model_file_path = os.path.join(model_dir, \"empty_model.txt\")\n",
    "\n",
    "# Create an empty file\n",
    "with open(empty_model_file_path, 'w') as f:\n",
    "    f.write(\"\")  # Write nothing to create an empty file\n",
    "\n",
    "# Start an MLFlow run\n",
    "with mlflow.start_run() as run:\n",
    "    # Log the empty model file as an artifact\n",
    "    mlflow.log_artifact(empty_model_file_path, artifact_path=\"model\")\n",
    "\n",
    "    # Register the model\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "    mlflow.register_model(model_uri=model_uri, name=\"EmptyModel\")\n",
    "\n",
    "print(\"Empty model registered successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Register ChatGPT endpoint\n",
    "#\n",
    "\n",
    "import mlflow.pyfunc\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import mlflow.pyfunc\n",
    "\n",
    "# Define the endpoint details\n",
    "endpoint_url = \"https://api.openai.com/v1/chat/completions\"\n",
    "api_key = OPENAI_API_KEY  #\"<your_openai_api_key>\"\n",
    "\n",
    "\n",
    "class ChatGPTModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, endpoint_url, api_key):\n",
    "        self.endpoint_url = endpoint_url\n",
    "        self.api_key = api_key\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        # Convert input to a list of strings (assumes DataFrame or Series input)\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            messages = model_input.iloc[:, 0].tolist()\n",
    "        elif isinstance(model_input, pd.Series):\n",
    "            messages = model_input.tolist()\n",
    "        elif isinstance(model_input, list):\n",
    "            messages = model_input\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported input format for model_input\")\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": message} for message in messages],\n",
    "        }\n",
    "        response = requests.post(self.endpoint_url, headers=headers, json=payload)\n",
    "        \n",
    "        # Raise an error for bad HTTP responses\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Extract the API response\n",
    "        return [choice[\"message\"][\"content\"] for choice in response.json()[\"choices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe65edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the wrapped model to a local directory\n",
    "model_path = \"chatgpt_model\"\n",
    "mlflow.pyfunc.save_model(\n",
    "    path=model_path,\n",
    "    python_model=ChatGPTModelWrapper(endpoint_url, api_key),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19138d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log and register the model\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"chatgpt_model\",\n",
    "        python_model=ChatGPTModelWrapper(endpoint_url, api_key),\n",
    "        registered_model_name=\"ChatGPT_Model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902bfd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "\n",
    "# Load the registered model\n",
    "model = mlflow.pyfunc.load_model(\"models:/ChatGPT_Model/latest\")\n",
    "\n",
    "# Test predictions\n",
    "input_data = pd.DataFrame([\"Hello, how are you?\"], columns=[\"prompt\"])\n",
    "result = model.predict(input_data)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
